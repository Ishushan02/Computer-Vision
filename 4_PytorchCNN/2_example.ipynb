{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "481a2d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e1dfccfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(\"Apple GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA GPU\")\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aff2d457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.286,), std=(0.353,))\n",
      "           ) Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.286,), std=(0.353,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.2860,), std=(0.3530,))\n",
    "])\n",
    "\n",
    "\n",
    "trainData = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "testData = datasets.FashionMNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=transform,\n",
    "    download=True,\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "print(trainData, testData,) #trainData.classes, trainData.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "62b5c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData.classes = trainData.class_to_idx\n",
    "testData.classes = testData.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e1b99291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,\n",
       "            0,  13,  73,   0,   0,   1,   4,   0,   0,   0,   0,   1,   1,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,   0,\n",
       "           36, 136, 127,  62,  54,   0,   0,   0,   1,   3,   4,   0,   0,   3],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,\n",
       "          102, 204, 176, 134, 144, 123,  23,   0,   0,   0,   0,  12,  10,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          155, 236, 207, 178, 107, 156, 161, 109,  64,  23,  77, 130,  72,  15],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   0,  69,\n",
       "          207, 223, 218, 216, 216, 163, 127, 121, 122, 146, 141,  88, 172,  66],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   1,   1,   0, 200,\n",
       "          232, 232, 233, 229, 223, 223, 215, 213, 164, 127, 123, 196, 229,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 183,\n",
       "          225, 216, 223, 228, 235, 227, 224, 222, 224, 221, 223, 245, 173,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 193,\n",
       "          228, 218, 213, 198, 180, 212, 210, 211, 213, 223, 220, 243, 202,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   1,   3,   0,  12, 219,\n",
       "          220, 212, 218, 192, 169, 227, 208, 218, 224, 212, 226, 197, 209,  52],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   6,   0,  99, 244,\n",
       "          222, 220, 218, 203, 198, 221, 215, 213, 222, 220, 245, 119, 167,  56],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,   0,   0,  55, 236,\n",
       "          228, 230, 228, 240, 232, 213, 218, 223, 234, 217, 217, 209,  92,   0],\n",
       "         [  0,   0,   1,   4,   6,   7,   2,   0,   0,   0,   0,   0, 237, 226,\n",
       "          217, 223, 222, 219, 222, 221, 216, 223, 229, 215, 218, 255,  77,   0],\n",
       "         [  0,   3,   0,   0,   0,   0,   0,   0,   0,  62, 145, 204, 228, 207,\n",
       "          213, 221, 218, 208, 211, 218, 224, 223, 219, 215, 224, 244, 159,   0],\n",
       "         [  0,   0,   0,   0,  18,  44,  82, 107, 189, 228, 220, 222, 217, 226,\n",
       "          200, 205, 211, 230, 224, 234, 176, 188, 250, 248, 233, 238, 215,   0],\n",
       "         [  0,  57, 187, 208, 224, 221, 224, 208, 204, 214, 208, 209, 200, 159,\n",
       "          245, 193, 206, 223, 255, 255, 221, 234, 221, 211, 220, 232, 246,   0],\n",
       "         [  3, 202, 228, 224, 221, 211, 211, 214, 205, 205, 205, 220, 240,  80,\n",
       "          150, 255, 229, 221, 188, 154, 191, 210, 204, 209, 222, 228, 225,   0],\n",
       "         [ 98, 233, 198, 210, 222, 229, 229, 234, 249, 220, 194, 215, 217, 241,\n",
       "           65,  73, 106, 117, 168, 219, 221, 215, 217, 223, 223, 224, 229,  29],\n",
       "         [ 75, 204, 212, 204, 193, 205, 211, 225, 216, 185, 197, 206, 198, 213,\n",
       "          240, 195, 227, 245, 239, 223, 218, 212, 209, 222, 220, 221, 230,  67],\n",
       "         [ 48, 203, 183, 194, 213, 197, 185, 190, 194, 192, 202, 214, 219, 221,\n",
       "          220, 236, 225, 216, 199, 206, 186, 181, 177, 172, 181, 205, 206, 115],\n",
       "         [  0, 122, 219, 193, 179, 171, 183, 196, 204, 210, 213, 207, 211, 210,\n",
       "          200, 196, 194, 191, 195, 191, 198, 192, 176, 156, 167, 177, 210,  92],\n",
       "         [  0,   0,  74, 189, 212, 191, 175, 172, 175, 181, 185, 188, 189, 188,\n",
       "          193, 198, 204, 209, 210, 210, 211, 188, 188, 194, 192, 216, 170,   0],\n",
       "         [  2,   0,   0,   0,  66, 200, 222, 237, 239, 242, 246, 243, 244, 221,\n",
       "          220, 193, 191, 179, 182, 182, 181, 176, 166, 168,  99,  58,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,  40,  61,  44,  72,  41,  35,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "         [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "        dtype=torch.uint8),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.data[0], trainData.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f0ca8a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, infeatures, hiddenfeatures, outfeatures):\n",
    "        super().__init__()\n",
    "        self.cnnModule1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=infeatures, out_channels=hiddenfeatures, kernel_size=2, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.cnnModule2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hiddenfeatures, out_channels=hiddenfeatures, kernel_size=2, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features= 4 * hiddenfeatures, out_features=outfeatures)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnnModule1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.cnnModule2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "model = CNNModel(infeatures=1, hiddenfeatures=10, outfeatures=10)\n",
    "# model.to(device)\n",
    "test = torch.rand(1, 1, 28, 28)\n",
    "model(test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c61e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    def __init__(self, data, scale=10.0):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X, y = self.data[idx]\n",
    "        # print(X, y)\n",
    "\n",
    "\n",
    "        return (\n",
    "            torch.tensor(X, dtype=torch.float32),\n",
    "            torch.tensor(y, dtype=torch.long)\n",
    "        )\n",
    "    \n",
    "\n",
    "trainDataset = FashionDataset(trainData)\n",
    "testDataset = FashionDataset(testData)\n",
    "\n",
    "# trainDataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "61d050ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]:   0%|          | 0/938 [00:00<?, ?it/s]/var/folders/y8/q2s37ndx6tg3lpzp3vp8xk_r0000gn/T/ipykernel_13679/3139814318.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(X, dtype=torch.float32),\n",
      "Epoch [1/10]: 100%|██████████| 938/938 [00:05<00:00, 164.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.5458778526 | test loss 0.4443813825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 938/938 [00:05<00:00, 169.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.4294564952 | test loss 0.4309619782 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 938/938 [00:05<00:00, 161.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.4007651464 | test loss 0.4126595892 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 938/938 [00:05<00:00, 162.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3885427569 | test loss 0.4467677489 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 938/938 [00:05<00:00, 170.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3835804174 | test loss 0.4161033143 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 938/938 [00:06<00:00, 156.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3739384150 | test loss 0.4100381116 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 938/938 [00:05<00:00, 167.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3739987412 | test loss 0.3939076703 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 938/938 [00:05<00:00, 161.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3686160824 | test loss 0.4041291331 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 938/938 [00:05<00:00, 174.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3658026204 | test loss 0.4593518131 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 938/938 [00:05<00:00, 183.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train Loss 0.3663259915 | test loss 0.4359558935 \n"
     ]
    }
   ],
   "source": [
    "model = CNNModel(infeatures=1, hiddenfeatures=64, outfeatures=10)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "lossFn = CrossEntropyLoss()\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "trainDataLoader = DataLoader(trainDataset, batch_size=64, shuffle=True)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# print(len(trainDataLoader))\n",
    "for each_epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    loop = tqdm(trainDataLoader, desc=f\"Epoch [{each_epoch+1}/{epochs}]\")\n",
    "    trainLoss = 0.0\n",
    "    validLoss = 0.0\n",
    "    for batchX, batchY in loop:\n",
    "        # print(batchX.shape, batchY.shape)\n",
    "        batchX = batchX.to(device)\n",
    "        batchY = batchY.to(device)\n",
    "\n",
    "        pred = model(batchX).to(device)\n",
    "        pred = pred.squeeze()\n",
    "\n",
    "        loss = lossFn(pred, batchY)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        trainLoss += loss.item()\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batchX, batchY in testDataLoader:\n",
    "            batchX = batchX.to(device)\n",
    "            batchY = batchY.to(device)\n",
    "\n",
    "            pred = model(batchX).to(device)\n",
    "            pred = pred.squeeze()\n",
    "\n",
    "            loss = lossFn(pred, batchY)\n",
    "\n",
    "            validLoss += loss.item()\n",
    "        #     break\n",
    "        # break\n",
    "    trainLoss = trainLoss/len(trainDataLoader)\n",
    "    validLoss = validLoss/len(testDataLoader)\n",
    "\n",
    "    \n",
    "    loop.write(f\" train Loss {trainLoss:.10f} | test loss {validLoss:.10f} \")\n",
    "\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4128298",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

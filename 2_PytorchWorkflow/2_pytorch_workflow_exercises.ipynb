{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/01_pytorch_workflow_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8LsPXZti9Sw"
      },
      "source": [
        "# 01. PyTorch Workflow Exercise Template\n",
        "\n",
        "The following is a template for the PyTorch workflow exercises.\n",
        "\n",
        "It's only starter code and it's your job to fill in the blanks.\n",
        "\n",
        "Because of the flexibility of PyTorch, there may be more than one way to answer the question.\n",
        "\n",
        "Don't worry about trying to be *right* just try writing code that suffices the question.\n",
        "\n",
        "You can see one form of [solutions on GitHub](https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/solutions) (but try the exercises below yourself first!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Glu2fM4dkNlx"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LqKhXY26m31s"
      },
      "outputs": [],
      "source": [
        "# Setup device-agnostic code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7HUhxCxjeBx"
      },
      "source": [
        "## 1. Create a straight line dataset using the linear regression formula (`weight * X + bias`).\n",
        "  * Set `weight=0.3` and `bias=0.9` there should be at least 100 datapoints total. \n",
        "  * Split the data into 80% training, 20% testing.\n",
        "  * Plot the training and testing data so it becomes visual.\n",
        "\n",
        "Your output of the below cell should look something like:\n",
        "```\n",
        "Number of X samples: 100\n",
        "Number of y samples: 100\n",
        "First 10 X & y samples:\n",
        "X: tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
        "        0.0900])\n",
        "y: tensor([0.9000, 0.9030, 0.9060, 0.9090, 0.9120, 0.9150, 0.9180, 0.9210, 0.9240,\n",
        "        0.9270])\n",
        "```\n",
        "\n",
        "Of course the numbers in `X` and `y` may be different but ideally they're created using the linear regression formula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KbDG5MV7jhvE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of X samples: 99900\n",
            "Number of y samples: 99900\n",
            "First 10 X & y samples:\n",
            "X: tensor([1.0000, 1.0100, 1.0200, 1.0300, 1.0400, 1.0500, 1.0600, 1.0700, 1.0800,\n",
            "        1.0900])\n",
            "y: tensor([1.2000, 1.2030, 1.2060, 1.2090, 1.2120, 1.2150, 1.2180, 1.2210, 1.2240,\n",
            "        1.2270])\n"
          ]
        }
      ],
      "source": [
        "# Create the data parameters\n",
        "X = torch.arange(1, 1000, 0.01)\n",
        "\n",
        "# Make X and y using linear regression feature\n",
        "y = 0.3 * X + 0.9\n",
        "\n",
        "print(f\"Number of X samples: {len(X)}\")\n",
        "print(f\"Number of y samples: {len(y)}\")\n",
        "print(f\"First 10 X & y samples:\\nX: {X[:10]}\\ny: {y[:10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GlwtT1djkmLw"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing\n",
        "train_size = int(0.8 * len(X))\n",
        "\n",
        "trainX, trainY = X[:train_size], y[:train_size]\n",
        "testX, testY = X[train_size:], y[train_size:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "29iQZFNhlYJ-"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x17c61e190>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the training and testing data \n",
        "\n",
        "plt.scatter(trainX, y = trainY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImZoe3v8jif8"
      },
      "source": [
        "## 2. Build a PyTorch model by subclassing `nn.Module`. \n",
        "  * Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`. \n",
        "  * Implement the `forward()` method to compute the linear regression function you used to create the dataset in 1. \n",
        "  * Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
        "  * **Note:** If you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qzd__Y5rjtB8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Epoch:0 Train Loss is 139.523193359375 and test Loss is 303.1329650878906\n",
            " Epoch:1 Train Loss is 135.50723266601562 and test Loss is 294.12200927734375\n",
            " Epoch:2 Train Loss is 131.49127197265625 and test Loss is 285.1110534667969\n",
            " Epoch:3 Train Loss is 127.47532653808594 and test Loss is 276.1000671386719\n",
            " Epoch:4 Train Loss is 123.45938110351562 and test Loss is 267.0891418457031\n",
            " Epoch:5 Train Loss is 119.44342803955078 and test Loss is 258.0782165527344\n",
            " Epoch:6 Train Loss is 115.42747497558594 and test Loss is 249.0672607421875\n",
            " Epoch:7 Train Loss is 111.4115219116211 and test Loss is 240.0562744140625\n",
            " Epoch:8 Train Loss is 107.39556884765625 and test Loss is 231.04534912109375\n",
            " Epoch:9 Train Loss is 103.37963104248047 and test Loss is 222.03440856933594\n",
            " Epoch:10 Train Loss is 99.36367797851562 and test Loss is 213.02345275878906\n",
            " Epoch:11 Train Loss is 95.34772491455078 and test Loss is 204.0124969482422\n",
            " Epoch:12 Train Loss is 91.33177185058594 and test Loss is 195.00155639648438\n",
            " Epoch:13 Train Loss is 87.31582641601562 and test Loss is 185.9906005859375\n",
            " Epoch:14 Train Loss is 83.29988861083984 and test Loss is 176.9796600341797\n",
            " Epoch:15 Train Loss is 79.28392028808594 and test Loss is 167.9686737060547\n",
            " Epoch:16 Train Loss is 75.26797485351562 and test Loss is 158.957763671875\n",
            " Epoch:17 Train Loss is 71.25202941894531 and test Loss is 149.94679260253906\n",
            " Epoch:18 Train Loss is 67.23607635498047 and test Loss is 140.9358367919922\n",
            " Epoch:19 Train Loss is 63.22011947631836 and test Loss is 131.92489624023438\n",
            " Epoch:20 Train Loss is 59.20417404174805 and test Loss is 122.91392517089844\n",
            " Epoch:21 Train Loss is 55.1882209777832 and test Loss is 113.9029769897461\n",
            " Epoch:22 Train Loss is 51.17226791381836 and test Loss is 104.89203643798828\n",
            " Epoch:23 Train Loss is 47.15631103515625 and test Loss is 95.88106536865234\n",
            " Epoch:24 Train Loss is 43.140357971191406 and test Loss is 86.8701171875\n",
            " Epoch:25 Train Loss is 39.124412536621094 and test Loss is 77.85916900634766\n",
            " Epoch:26 Train Loss is 35.10845947265625 and test Loss is 68.84819793701172\n",
            " Epoch:27 Train Loss is 31.092504501342773 and test Loss is 59.837257385253906\n",
            " Epoch:28 Train Loss is 27.07655143737793 and test Loss is 50.8263053894043\n",
            " Epoch:29 Train Loss is 23.060604095458984 and test Loss is 41.81534194946289\n",
            " Epoch:30 Train Loss is 19.044647216796875 and test Loss is 32.804405212402344\n",
            " Epoch:31 Train Loss is 15.028705596923828 and test Loss is 23.7934513092041\n",
            " Epoch:32 Train Loss is 11.012755393981934 and test Loss is 14.782523155212402\n",
            " Epoch:33 Train Loss is 6.9968109130859375 and test Loss is 5.771578788757324\n",
            " Epoch:34 Train Loss is 2.9808664321899414 and test Loss is 3.239372730255127\n",
            " Epoch:35 Train Loss is 1.185497760772705 and test Loss is 10.50332260131836\n",
            " Epoch:36 Train Loss is 4.323493957519531 and test Loss is 16.11505126953125\n",
            " Epoch:37 Train Loss is 6.80663537979126 and test Loss is 20.239547729492188\n",
            " Epoch:38 Train Loss is 8.637971878051758 and test Loss is 23.02895164489746\n",
            " Epoch:39 Train Loss is 9.878005027770996 and test Loss is 24.620298385620117\n",
            " Epoch:40 Train Loss is 10.585901260375977 and test Loss is 25.136571884155273\n",
            " Epoch:41 Train Loss is 10.815778732299805 and test Loss is 24.6879825592041\n",
            " Epoch:42 Train Loss is 10.616525650024414 and test Loss is 23.37331199645996\n",
            " Epoch:43 Train Loss is 10.0321626663208 and test Loss is 21.28117561340332\n",
            " Epoch:44 Train Loss is 9.102388381958008 and test Loss is 18.491180419921875\n",
            " Epoch:45 Train Loss is 7.863171100616455 and test Loss is 15.075004577636719\n",
            " Epoch:46 Train Loss is 6.347668170928955 and test Loss is 11.097525596618652\n",
            " Epoch:47 Train Loss is 4.588047504425049 and test Loss is 6.619056701660156\n",
            " Epoch:48 Train Loss is 2.6233131885528564 and test Loss is 1.7024316787719727\n",
            " Epoch:49 Train Loss is 0.5974470376968384 and test Loss is 3.443394899368286\n",
            " Epoch:50 Train Loss is 1.9385606050491333 and test Loss is 7.159694194793701\n",
            " Epoch:51 Train Loss is 3.594285011291504 and test Loss is 9.591035842895508\n",
            " Epoch:52 Train Loss is 4.677376747131348 and test Loss is 10.867240905761719\n",
            " Epoch:53 Train Loss is 5.24567985534668 and test Loss is 11.10490894317627\n",
            " Epoch:54 Train Loss is 5.351172924041748 and test Loss is 10.408829689025879\n",
            " Epoch:55 Train Loss is 5.040533542633057 and test Loss is 8.873111724853516\n",
            " Epoch:56 Train Loss is 4.355721473693848 and test Loss is 6.582378387451172\n",
            " Epoch:57 Train Loss is 3.334428548812866 and test Loss is 3.6126344203948975\n",
            " Epoch:58 Train Loss is 2.010558605194092 and test Loss is 0.04502694681286812\n",
            " Epoch:59 Train Loss is 0.4145413041114807 and test Loss is 4.097352504730225\n",
            " Epoch:60 Train Loss is 1.544398546218872 and test Loss is 6.9587602615356445\n",
            " Epoch:61 Train Loss is 2.7745819091796875 and test Loss is 8.6453857421875\n",
            " Epoch:62 Train Loss is 3.512880802154541 and test Loss is 9.26778507232666\n",
            " Epoch:63 Train Loss is 3.7867531776428223 and test Loss is 8.930794715881348\n",
            " Epoch:64 Train Loss is 3.6389713287353516 and test Loss is 7.7312188148498535\n",
            " Epoch:65 Train Loss is 3.1132469177246094 and test Loss is 5.758960723876953\n",
            " Epoch:66 Train Loss is 2.2554776668548584 and test Loss is 3.102234363555908\n",
            " Epoch:67 Train Loss is 1.133718490600586 and test Loss is 0.12124832719564438\n",
            " Epoch:68 Train Loss is 0.4496094584465027 and test Loss is 2.1118109226226807\n",
            " Epoch:69 Train Loss is 1.3360984325408936 and test Loss is 2.9932315349578857\n",
            " Epoch:70 Train Loss is 1.7283011674880981 and test Loss is 2.876774787902832\n",
            " Epoch:71 Train Loss is 1.675817608833313 and test Loss is 1.8625915050506592\n",
            " Epoch:72 Train Loss is 1.2232733964920044 and test Loss is 0.04821900278329849\n",
            " Epoch:73 Train Loss is 0.4108012318611145 and test Loss is 2.5077521800994873\n",
            " Epoch:74 Train Loss is 0.897473156452179 and test Loss is 4.005354881286621\n",
            " Epoch:75 Train Loss is 1.5094449520111084 and test Loss is 4.494487285614014\n",
            " Epoch:76 Train Loss is 1.7165696620941162 and test Loss is 4.065614223480225\n",
            " Epoch:77 Train Loss is 1.5354660749435425 and test Loss is 2.81746244430542\n",
            " Epoch:78 Train Loss is 1.020902395248413 and test Loss is 0.8714959025382996\n",
            " Epoch:79 Train Loss is 0.3485468924045563 and test Loss is 1.3455008268356323\n",
            " Epoch:80 Train Loss is 0.9868113994598389 and test Loss is 2.4232444763183594\n",
            " Epoch:81 Train Loss is 1.4660980701446533 and test Loss is 2.4761550426483154\n",
            " Epoch:82 Train Loss is 1.4887117147445679 and test Loss is 1.6071429252624512\n",
            " Epoch:83 Train Loss is 1.1005147695541382 and test Loss is 0.09120334684848785\n",
            " Epoch:84 Train Loss is 0.3427952229976654 and test Loss is 2.5131607055664062\n",
            " Epoch:85 Train Loss is 0.9016938805580139 and test Loss is 3.885261058807373\n",
            " Epoch:86 Train Loss is 1.4633221626281738 and test Loss is 4.255032539367676\n",
            " Epoch:87 Train Loss is 1.6198410987854004 and test Loss is 3.714197874069214\n",
            " Epoch:88 Train Loss is 1.3924543857574463 and test Loss is 2.3644895553588867\n",
            " Epoch:89 Train Loss is 0.8443525433540344 and test Loss is 0.3449488580226898\n",
            " Epoch:90 Train Loss is 0.2826075255870819 and test Loss is 1.377197265625\n",
            " Epoch:91 Train Loss is 0.9901573657989502 and test Loss is 2.001833438873291\n",
            " Epoch:92 Train Loss is 1.267382264137268 and test Loss is 1.6393364667892456\n",
            " Epoch:93 Train Loss is 1.1047509908676147 and test Loss is 0.3889300525188446\n",
            " Epoch:94 Train Loss is 0.5464633107185364 and test Loss is 1.6600620746612549\n",
            " Epoch:95 Train Loss is 0.5823311805725098 and test Loss is 2.7755885124206543\n",
            " Epoch:96 Train Loss is 1.0092684030532837 and test Loss is 2.942018508911133\n",
            " Epoch:97 Train Loss is 1.0770647525787354 and test Loss is 2.2447104454040527\n",
            " Epoch:98 Train Loss is 0.799821138381958 and test Loss is 0.8107352256774902\n",
            " Epoch:99 Train Loss is 0.32676997780799866 and test Loss is 0.9402568340301514\n"
          ]
        }
      ],
      "source": [
        "# Create PyTorch linear regression model by subclassing nn.Module\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "\n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(0.1 * torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
        "        self.bias = nn.Parameter(0.1 * torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.weights * x + self.bias\n",
        "\n",
        "model1 = LinearRegression()\n",
        "\n",
        "lossFn = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(model1.parameters(), lr=0.01)\n",
        "\n",
        "for each_epoch in range(100):\n",
        "\n",
        "    model1.train()\n",
        "    y_pred = model1(trainX)\n",
        "    loss = lossFn(y_pred, trainY)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model1.eval()\n",
        "    with torch.inference_mode():\n",
        "        test = model1(testX)\n",
        "        test_loss = lossFn(test, testY)\n",
        "    \n",
        "    print(f\" Epoch:{each_epoch} Train Loss is {loss} and test Loss is {test_loss}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4j4TM18jwa7"
      },
      "source": [
        "## 4. Make predictions with the trained model on the test data.\n",
        "  * Visualize these predictions against the original training and testing data (**note:** you may need to make sure the predictions are *not* on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbMPK5Qjjyx_"
      },
      "outputs": [],
      "source": [
        "# Make predictions with the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3BdmQaDpFo8"
      },
      "outputs": [],
      "source": [
        "# Plot the predictions (these may need to be on a specific device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2OnlMWKjzX8"
      },
      "source": [
        "## 5. Save your trained model's `state_dict()` to file.\n",
        "  * Create a new instance of your model class you made in 2. and load in the `state_dict()` you just saved to it.\n",
        "  * Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "hgxhgD14qr-i"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# 1. Create models directory \n",
        "modelPath = Path(\"test_model.pth\")\n",
        "torch.save(model1.state_dict(), f=modelPath)\n",
        "# 3. Save the model state dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9vTgiLRrJ7T"
      },
      "outputs": [],
      "source": [
        "# Create new instance of model and load saved state dict (make sure to put it on the target device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UGX3VebrVtI"
      },
      "outputs": [],
      "source": [
        "# Make predictions with loaded model and compare them to the previous\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNYzatJtFkfUqqdiR6rYwVL",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "01_pytorch_workflow_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

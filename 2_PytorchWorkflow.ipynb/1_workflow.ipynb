{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:  torch.Size([100000, 1]) Shape of Y:  torch.Size([100000, 1])\n",
      "tensor([0.]) tensor([2.])\n",
      "tensor([0.0010]) tensor([2.0006])\n",
      "tensor([0.0020]) tensor([2.0012])\n",
      "tensor([0.0030]) tensor([2.0018])\n",
      "tensor([0.0040]) tensor([2.0024])\n",
      "tensor([0.0050]) tensor([2.0030])\n",
      "tensor([0.0060]) tensor([2.0036])\n",
      "tensor([0.0070]) tensor([2.0042])\n",
      "tensor([0.0080]) tensor([2.0048])\n",
      "tensor([0.0090]) tensor([2.0054])\n"
     ]
    }
   ],
   "source": [
    "weight = 0.6\n",
    "bias = 2\n",
    "\n",
    "X = torch.arange(start=0, end=100, step=0.001).unsqueeze(dim=1)\n",
    "Y = weight * X + bias\n",
    "\n",
    "print(\"Shape of X: \", X.shape,\"Shape of Y: \",  Y.shape, )\n",
    "\n",
    "for i in range(len(X[:10])):\n",
    "    print(X[i], Y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Size:  85000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([85000, 1]), torch.Size([15000, 1]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_len = int(0.85 * len(X))\n",
    "print(\"Training Size: \", train_len)\n",
    "\n",
    "train_X, train_y = X[:train_len], Y[:train_len]\n",
    "test_X, test_Y = X[train_len:], Y[train_len:]\n",
    "\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plotData(X, Y, c = 'b'):\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.scatter(X, Y, s = 3, c = c )\n",
    "    plt.show()\n",
    "\n",
    "plotData(train_X, train_y, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "        self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x:torch.tensor) -> torch.tensor:\n",
    "        return self.weights * x + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters:  [Parameter containing:\n",
      "tensor([0.3367], requires_grad=True), Parameter containing:\n",
      "tensor([0.1288], requires_grad=True)]\n",
      "State Dict:  OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_test = LinearRegression()\n",
    "\n",
    "print(\"Parameters: \", list(model_test.parameters()))\n",
    "print(\"State Dict: \", model_test.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[28.7475],\n",
       "         [28.7478],\n",
       "         [28.7482],\n",
       "         [28.7485],\n",
       "         [28.7488],\n",
       "         [28.7492],\n",
       "         [28.7495],\n",
       "         [28.7498],\n",
       "         [28.7502],\n",
       "         [28.7505]]),\n",
       " tensor([[53.0000],\n",
       "         [53.0006],\n",
       "         [53.0012],\n",
       "         [53.0018],\n",
       "         [53.0024],\n",
       "         [53.0030],\n",
       "         [53.0036],\n",
       "         [53.0042],\n",
       "         [53.0048],\n",
       "         [53.0054]]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicting value without training the model\n",
    "\n",
    "with torch.inference_mode():\n",
    "    y_pred = model_test(test_X)\n",
    "\n",
    "# We can do the same this using\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model_test(test_X)\n",
    "\n",
    "y_pred[:10], test_Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, Train loss is 13.061718940734863 ans test loss is 13.094616889953613\n",
      "[OrderedDict([('weights', tensor([0.7617])), ('bias', tensor([0.1388]))])]\n",
      " Epoch: 20, Train loss is 9.004914283752441 ans test loss is 21.899574279785156\n",
      "[OrderedDict([('weights', tensor([0.8566])), ('bias', tensor([0.1597]))])]\n",
      " Epoch: 40, Train loss is 6.842517852783203 ans test loss is 26.587886810302734\n",
      "[OrderedDict([('weights', tensor([0.9072])), ('bias', tensor([0.1751]))])]\n",
      " Epoch: 60, Train loss is 5.253997325897217 ans test loss is 30.029743194580078\n",
      "[OrderedDict([('weights', tensor([0.9442])), ('bias', tensor([0.1883]))])]\n",
      " Epoch: 80, Train loss is 3.9681782722473145 ans test loss is 32.814334869384766\n",
      "[OrderedDict([('weights', tensor([0.9742])), ('bias', tensor([0.2002]))])]\n",
      " Epoch: 100, Train loss is 2.8747856616973877 ans test loss is 35.18120574951172\n",
      "[OrderedDict([('weights', tensor([0.9997])), ('bias', tensor([0.2112]))])]\n",
      " Epoch: 120, Train loss is 1.9165793657302856 ans test loss is 37.25468063354492\n",
      "[OrderedDict([('weights', tensor([1.0220])), ('bias', tensor([0.2214]))])]\n",
      " Epoch: 140, Train loss is 1.0596033334732056 ans test loss is 39.10847091674805\n",
      "[OrderedDict([('weights', tensor([1.0419])), ('bias', tensor([0.2311]))])]\n",
      " Epoch: 160, Train loss is 4.901642799377441 ans test loss is 30.73464012145996\n",
      "[OrderedDict([('weights', tensor([0.9513])), ('bias', tensor([0.2410]))])]\n",
      " Epoch: 180, Train loss is 3.727576494216919 ans test loss is 33.276634216308594\n",
      "[OrderedDict([('weights', tensor([0.9786])), ('bias', tensor([0.2524]))])]\n",
      " Epoch: 200, Train loss is 2.7150650024414062 ans test loss is 35.46794891357422\n",
      "[OrderedDict([('weights', tensor([1.0022])), ('bias', tensor([0.2629]))])]\n",
      " Epoch: 220, Train loss is 1.8193738460540771 ans test loss is 37.405757904052734\n",
      "[OrderedDict([('weights', tensor([1.0231])), ('bias', tensor([0.2728]))])]\n",
      " Epoch: 240, Train loss is 1.0129865407943726 ans test loss is 39.149803161621094\n",
      "[OrderedDict([('weights', tensor([1.0418])), ('bias', tensor([0.2822]))])]\n",
      " Epoch: 260, Train loss is 3.0660204887390137 ans test loss is 34.67087173461914\n",
      "[OrderedDict([('weights', tensor([0.9933])), ('bias', tensor([0.2912]))])]\n",
      " Epoch: 280, Train loss is 2.161069393157959 ans test loss is 36.628780364990234\n",
      "[OrderedDict([('weights', tensor([1.0144])), ('bias', tensor([0.3011]))])]\n",
      " Epoch: 300, Train loss is 1.3487586975097656 ans test loss is 38.38565444946289\n",
      "[OrderedDict([('weights', tensor([1.0332])), ('bias', tensor([0.3105]))])]\n",
      " Epoch: 320, Train loss is 2.375152111053467 ans test loss is 36.14142990112305\n",
      "[OrderedDict([('weights', tensor([1.0089])), ('bias', tensor([0.3193]))])]\n",
      " Epoch: 340, Train loss is 1.559401273727417 ans test loss is 37.90578079223633\n",
      "[OrderedDict([('weights', tensor([1.0279])), ('bias', tensor([0.3287]))])]\n",
      " Epoch: 360, Train loss is 0.8188961148262024 ans test loss is 36.231510162353516\n",
      "[OrderedDict([('weights', tensor([1.0097])), ('bias', tensor([0.3373]))])]\n",
      " Epoch: 380, Train loss is 1.5277395248413086 ans test loss is 37.95360565185547\n",
      "[OrderedDict([('weights', tensor([1.0282])), ('bias', tensor([0.3467]))])]\n",
      " Epoch: 400, Train loss is 0.8041056990623474 ans test loss is 35.05707550048828\n",
      "[OrderedDict([('weights', tensor([0.9968])), ('bias', tensor([0.3550]))])]\n",
      " Epoch: 420, Train loss is 2.0260252952575684 ans test loss is 36.84810256958008\n",
      "[OrderedDict([('weights', tensor([1.0160])), ('bias', tensor([0.3645]))])]\n",
      " Epoch: 440, Train loss is 1.2764896154403687 ans test loss is 38.46880340576172\n",
      "[OrderedDict([('weights', tensor([1.0335])), ('bias', tensor([0.3736]))])]\n",
      " Epoch: 460, Train loss is 2.6627278327941895 ans test loss is 35.441802978515625\n",
      "[OrderedDict([('weights', tensor([1.0006])), ('bias', tensor([0.3820]))])]\n",
      " Epoch: 480, Train loss is 1.8747870922088623 ans test loss is 37.14582443237305\n",
      "[OrderedDict([('weights', tensor([1.0190])), ('bias', tensor([0.3912]))])]\n",
      " Epoch: 500, Train loss is 1.158085823059082 ans test loss is 38.69529724121094\n",
      "[OrderedDict([('weights', tensor([1.0356])), ('bias', tensor([0.4001]))])]\n",
      " Epoch: 520, Train loss is 4.161066055297852 ans test loss is 32.14966583251953\n",
      "[OrderedDict([('weights', tensor([0.9648])), ('bias', tensor([0.4083]))])]\n",
      " Epoch: 540, Train loss is 3.252277135848999 ans test loss is 34.11589813232422\n",
      "[OrderedDict([('weights', tensor([0.9859])), ('bias', tensor([0.4183]))])]\n",
      " Epoch: 560, Train loss is 2.4431381225585938 ans test loss is 35.86589813232422\n",
      "[OrderedDict([('weights', tensor([1.0047])), ('bias', tensor([0.4277]))])]\n",
      " Epoch: 580, Train loss is 1.7112315893173218 ans test loss is 37.448368072509766\n",
      "[OrderedDict([('weights', tensor([1.0218])), ('bias', tensor([0.4367]))])]\n",
      " Epoch: 600, Train loss is 1.0413172245025635 ans test loss is 38.8963508605957\n",
      "[OrderedDict([('weights', tensor([1.0373])), ('bias', tensor([0.4452]))])]\n",
      " Epoch: 620, Train loss is 4.758310794830322 ans test loss is 30.796754837036133\n",
      "[OrderedDict([('weights', tensor([0.9497])), ('bias', tensor([0.4534]))])]\n",
      " Epoch: 640, Train loss is 3.8280844688415527 ans test loss is 32.809505462646484\n",
      "[OrderedDict([('weights', tensor([0.9713])), ('bias', tensor([0.4635]))])]\n",
      " Epoch: 660, Train loss is 3.005553722381592 ans test loss is 34.58856964111328\n",
      "[OrderedDict([('weights', tensor([0.9904])), ('bias', tensor([0.4730]))])]\n",
      " Epoch: 680, Train loss is 2.2652392387390137 ans test loss is 36.18926239013672\n",
      "[OrderedDict([('weights', tensor([1.0076])), ('bias', tensor([0.4820]))])]\n",
      " Epoch: 700, Train loss is 1.5902457237243652 ans test loss is 37.64826965332031\n",
      "[OrderedDict([('weights', tensor([1.0233])), ('bias', tensor([0.4906]))])]\n",
      " Epoch: 720, Train loss is 0.9684544205665588 ans test loss is 38.99189758300781\n",
      "[OrderedDict([('weights', tensor([1.0378])), ('bias', tensor([0.4988]))])]\n",
      " Epoch: 740, Train loss is 2.2752761840820312 ans test loss is 36.138282775878906\n",
      "[OrderedDict([('weights', tensor([1.0068])), ('bias', tensor([0.5067]))])]\n",
      " Epoch: 760, Train loss is 1.6186777353286743 ans test loss is 37.557395935058594\n",
      "[OrderedDict([('weights', tensor([1.0221])), ('bias', tensor([0.5152]))])]\n",
      " Epoch: 780, Train loss is 1.0130010843276978 ans test loss is 38.86607360839844\n",
      "[OrderedDict([('weights', tensor([1.0361])), ('bias', tensor([0.5233]))])]\n",
      " Epoch: 800, Train loss is 1.8068753480911255 ans test loss is 37.12910079956055\n",
      "[OrderedDict([('weights', tensor([1.0173])), ('bias', tensor([0.5311]))])]\n",
      " Epoch: 820, Train loss is 1.200609564781189 ans test loss is 38.439048767089844\n",
      "[OrderedDict([('weights', tensor([1.0314])), ('bias', tensor([0.5392]))])]\n",
      " Epoch: 840, Train loss is 4.242831707000732 ans test loss is 31.809467315673828\n",
      "[OrderedDict([('weights', tensor([0.9596])), ('bias', tensor([0.5462]))])]\n",
      " Epoch: 860, Train loss is 3.457197904586792 ans test loss is 33.508480072021484\n",
      "[OrderedDict([('weights', tensor([0.9779])), ('bias', tensor([0.5555]))])]\n",
      " Epoch: 880, Train loss is 2.7495808601379395 ans test loss is 35.038246154785156\n",
      "[OrderedDict([('weights', tensor([0.9943])), ('bias', tensor([0.5643]))])]\n",
      " Epoch: 900, Train loss is 2.10391902923584 ans test loss is 36.433631896972656\n",
      "[OrderedDict([('weights', tensor([1.0093])), ('bias', tensor([0.5727]))])]\n",
      " Epoch: 920, Train loss is 1.5089592933654785 ans test loss is 37.719078063964844\n",
      "[OrderedDict([('weights', tensor([1.0231])), ('bias', tensor([0.5808]))])]\n",
      " Epoch: 940, Train loss is 0.9564826488494873 ans test loss is 38.912391662597656\n",
      "[OrderedDict([('weights', tensor([1.0359])), ('bias', tensor([0.5885]))])]\n",
      " Epoch: 960, Train loss is 1.855809211730957 ans test loss is 36.946311950683594\n",
      "[OrderedDict([('weights', tensor([1.0146])), ('bias', tensor([0.5959]))])]\n",
      " Epoch: 980, Train loss is 1.2933716773986816 ans test loss is 38.16122817993164\n",
      "[OrderedDict([('weights', tensor([1.0277])), ('bias', tensor([0.6038]))])]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "lossFn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(params=model_test.parameters(), lr=0.01)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "for each_epoch in range(epochs):\n",
    "    model_test.train()\n",
    "\n",
    "    y_pred = model_test(train_X)\n",
    "\n",
    "    loss = lossFn(y_pred, train_y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model_test.eval()\n",
    "    with torch.inference_mode():\n",
    "        y_pred = model_test(test_X)\n",
    "        test_loss = lossFn(y_pred, test_Y)\n",
    "    if each_epoch % 20 == 0:\n",
    "        print(f\" Epoch: {each_epoch}, Train loss is {loss.item()} ans test loss is {test_loss.item()}\")\n",
    "        print([model_test.state_dict()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('weights', tensor([0.6148])), ('bias', tensor([0.6013]))])]\n"
     ]
    }
   ],
   "source": [
    "print([model_test.state_dict()])\n",
    "# with torch.no_grad():\n",
    "#     y_pred = model_test(test_Y)\n",
    "\n",
    "# y_pred[:10], test_Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the Model\n",
    "\n",
    "torch.save() \n",
    "\n",
    "torch.load() \n",
    "\n",
    "torch.nn.Module.load_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "modelPath = Path(\"model.pth\")\n",
    "torch.save(model_test.state_dict(), f=modelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLoaded = LinearRegression()\n",
    "modelLoaded.load_state_dict(torch.load(modelPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[52.8610],\n",
       "        [52.8616],\n",
       "        [52.8622],\n",
       "        ...,\n",
       "        [62.0815],\n",
       "        [62.0821],\n",
       "        [62.0827]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLoaded.eval()\n",
    "with torch.inference_mode():\n",
    "    ypred = modelLoaded(test_X)\n",
    "\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
